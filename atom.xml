<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Coding it my way</title>
  <link href="https://madhur.co.in/blog/"/>
 <updated>2022-01-01T12:18:30+05:30</updated>
 <id>https://madhur.co.in/blog/</id>
 <author>
   <name>Madhur Ahuja</name>
   <email>ahuja.madhur@gmail.com</email>
 </author>
 
 
 <entry>
   <title>Provision Redis cluster through Vagrant and Ansible</title>
   <link href="https://madhur.co.in/blog/2022/01/01/redis-cluster-ansible.html"/>
   <updated>2022-01-01T00:00:00+05:30</updated>
   <id>id:/blog/2022/01/01/redis-cluster-ansible</id>
   <content type="html">&lt;p&gt;If you want to provision a test redis cluster for yourself, I recently created an automated solution using &lt;a href=&quot;https://www.vagrantup.com/&quot;&gt;Vagrant&lt;/a&gt; and &lt;a href=&quot;https://www.ansible.com/&quot;&gt;Ansible&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Git clone the repository &lt;a href=&quot;https://github.com/madhur/redis-cluster-vagrant&quot;&gt;https://github.com/madhur/redis-cluster-vagrant&lt;/a&gt; and use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vagrant up&lt;/code&gt; command to bring up the five Centos 7 nodes.&lt;/p&gt;

&lt;p&gt;Once the nodes are up, the ansible playbook &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setup-redis.yml&lt;/code&gt; can be executed which will install redis on all the five nodes.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ansible-playbook playbooks/setup-redis.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The ansible playbook provisions four redis process on each node running on different ports.&lt;/p&gt;

&lt;p&gt;Once the redis is setup, the execute the below command by sshing into any of the nodes (ex &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vagrant ssh redis1&lt;/code&gt;) to form the cluster&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;redis-cli --cluster create 192.168.56.10:7000 192.168.56.10:7001 192.168.56.11:7002 192.168.56.11:7003 192.168.56.12:7004 192.168.56.12:7005 192.168.56.13:7006 192.168.56.13:7007 192.168.56.14:7008 192.168.56.14:7009 192.168.56.10:6008 192.168.56.10:6009 192.168.56.11:6000 192.168.56.11:6001 192.168.56.12:6006 192.168.56.12:6007 192.168.56.13:6004 192.168.56.13:6005 192.168.56.14:6002 192.168.56.14:6003  --cluster-replicas 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Cluster info and nodes output&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[vagrant@redis1 ~]$ redis-cli -c -p 7000
127.0.0.1:7000&amp;gt; cluster info
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:20
cluster_size:10
cluster_current_epoch:26
cluster_my_epoch:1
cluster_stats_messages_ping_sent:21962
cluster_stats_messages_pong_sent:21933
cluster_stats_messages_fail_sent:19
cluster_stats_messages_auth-ack_sent:6
cluster_stats_messages_update_sent:4
cluster_stats_messages_sent:43924
cluster_stats_messages_ping_received:21914
cluster_stats_messages_pong_received:21920
cluster_stats_messages_meet_received:19
cluster_stats_messages_fail_received:51
cluster_stats_messages_auth-req_received:6
cluster_stats_messages_received:43910
127.0.0.1:7000&amp;gt; cluster nodes
6e5264f6eb7430bf17255019d826a5e4358f6295 192.168.56.10:7001@17001 master - 0 1638032107272 2 connected 8192-9829
00073613e6b6227e63c503012846b89b9644d57e 192.168.56.10:6008@16008 master - 0 1638032106770 25 connected 14746-16383
cbf1264f74e929815df87cb83db7a68400a5bb6f 192.168.56.11:6001@16001 slave 6e5264f6eb7430bf17255019d826a5e4358f6295 0 1638032107000 2 connected
5ed583e52a38b5e7a01adf24b3048b18f5e03732 192.168.56.11:6000@16000 slave be3a72b4386d4c235717d11ae6d5cf456d9ae3cf 0 1638032107272 1 connected
1dab38a32885b6edaa84939ba1a8f21eb3b0756e 192.168.56.12:7004@17004 master - 0 1638032107675 5 connected 3277-4914
be3a72b4386d4c235717d11ae6d5cf456d9ae3cf 192.168.56.10:7000@17000 myself,master - 0 1638032102000 1 connected 0-1637
cc0bf33f88da4c0a987040c0abb61de9274e4c2e 192.168.56.11:7003@17003 master - 0 1638032107000 4 connected 9830-11468
d937a08e1ad1e81743a83a47d14d391aaf322cda 192.168.56.14:6003@16003 slave aa1fcb5c0660937662f0c70b89dfb09186ea0f4f 0 1638032106256 8 connected
996e270ea827c7a40aab9ec17713e10e80534d92 192.168.56.13:6005@16005 slave 38bda2c495194da1bc8db1d3f3aa5316a0c31332 0 1638032106971 6 connected
7e610c0b0ab6fc8a14cb618da205c587d6a451ca 192.168.56.11:7002@17002 master - 0 1638032106770 3 connected 1638-3276
0606dd06e50bc023d5c961de12ab9420ad2319bf 192.168.56.12:6007@16007 slave cc0bf33f88da4c0a987040c0abb61de9274e4c2e 0 1638032107675 4 connected
6ca58a8fd1a2b5418d60447f96101acc7dc229e1 192.168.56.13:6004@16004 slave 1dab38a32885b6edaa84939ba1a8f21eb3b0756e 0 1638032106669 5 connected
aa1fcb5c0660937662f0c70b89dfb09186ea0f4f 192.168.56.13:7007@17007 master - 0 1638032106465 8 connected 13107-14745
38bda2c495194da1bc8db1d3f3aa5316a0c31332 192.168.56.12:7005@17005 master - 0 1638032107675 6 connected 11469-13106
c53eb727d619d127336382736dae2f36b519ed1a 192.168.56.14:7009@17009 slave 00073613e6b6227e63c503012846b89b9644d57e 0 1638032107172 25 connected
8644049d5adb32c8570768d61186b6ea9307ca7a 192.168.56.10:6009@16009 master - 0 1638032107776 26 connected 6554-8191
45493186df74aea9ae31aa6d84421bbf1b0b18f1 192.168.56.14:7008@17008 slave 8644049d5adb32c8570768d61186b6ea9307ca7a 0 1638032106000 26 connected
5ba3d4ce175967027c23e48e884ca549222206b6 192.168.56.13:7006@17006 master - 0 1638032107172 7 connected 4915-6553
915aa483535504cc8ca4662bba40adbfabf95d95 192.168.56.12:6006@16006 slave 7e610c0b0ab6fc8a14cb618da205c587d6a451ca 0 1638032107172 3 connected
6f8ab10161f974f37a97b2e18a52d91878dc799d 192.168.56.14:6002@16002 slave 5ba3d4ce175967027c23e48e884ca549222206b6 0 1638032107776 7 connected
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Proxy nodejs requests through Proxy Server</title>
   <link href="https://madhur.co.in/blog/2021/12/12/proxy-nodejs-requests.html"/>
   <updated>2021-12-12T00:00:00+05:30</updated>
   <id>id:/blog/2021/12/12/proxy-nodejs-requests</id>
   <content type="html">&lt;p&gt;If you want to proxy all Nodejs HTTP requests through a  proxy server, just like JVM’s&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;-Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=8888
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the quickest solution, without modifying the application source code&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm i global-agent
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;GLOBAL_AGENT_HTTP_PROXY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;http://127.0.0.1:8888
node &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'global-agent/bootstrap'&lt;/span&gt; app.js
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will enable you to proxy all requests through proxy server running at 127.0.0.1 on port 8888, which could be &lt;a href=&quot;https://www.charlesproxy.com/&quot;&gt;Charles&lt;/a&gt; or &lt;a href=&quot;https://portswigger.net/burp/communitydownload&quot;&gt;Burp&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kernel Panic with AMD Ryzen 5600x on CentOS 7</title>
   <link href="https://madhur.co.in/blog/2021/11/27/linux-kernel-panic.html"/>
   <updated>2021-11-27T00:00:00+05:30</updated>
   <id>id:/blog/2021/11/27/linux-kernel-panic</id>
   <content type="html">&lt;p&gt;Recently, I upgraded my personal computer CPU from &lt;a href=&quot;https://ark.intel.com/content/www/us/en/ark/products/52214/intel-core-i72600k-processor-8m-cache-up-to-3-80-ghz.html&quot;&gt;Intel Core i7 2600K (SandyBridge)&lt;/a&gt; to &lt;a href=&quot;https://www.amd.com/en/products/cpu/amd-ryzen-5-5600x&quot;&gt;AMD Ryzen 5600x&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The older processor was a decade old and the accompanying board didn’t support new age SSDs such as &lt;a href=&quot;https://www.samsung.com/us/computing/memory-storage/solid-state-drives/980-pro-pcie-4-0-nvme-ssd-1tb-mz-v8p1t0b-am/&quot;&gt;Nvme PCI 4 SSD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, post upgradation, as soon as I booted my existing system running CentOS 7, I recieved a dreaded &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_panic&quot;&gt;kernel panic&lt;/a&gt; very similar to &lt;a href=&quot;https://en.wikipedia.org/wiki/Blue_screen_of_death&quot;&gt;BSOD in Windows&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kernel-panic.jpg&quot; height=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Turns out that latest AMD processors are not supported on Kernel 3.x which comes with CentOS 7. I had to upgrade it to Cent OS 8 which comes with Kernel 4.x&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Offload IO Intensive tasks to worker threads</title>
   <link href="https://madhur.co.in/blog/2021/11/20/offload-io-intensive-tasks-to-threads.html"/>
   <updated>2021-11-20T00:00:00+05:30</updated>
   <id>id:/blog/2021/11/20/offload-io-intensive-tasks-to-threads</id>
   <content type="html">&lt;p&gt;In most of the modern web REST implementations, much of the task is spent waiting on IO, for example waiting for data to be fetched from database or through remote REST service.&lt;/p&gt;

&lt;p&gt;When the application receives high traffic on a thread based application server, such as Tomcat, much of its threads are just waiting for data to come from database or remote REST service.&lt;/p&gt;

&lt;p&gt;This is inefficient because, you cannot increase the number of threads vertically in a single compute. Theoretically you can, but its just pure inefficient because most of those threads will be just blocked.&lt;/p&gt;

&lt;p&gt;Thus, in order to scale such applications, the better model is to offload this waiting to pool of worker threads. This will free up the Tomcat http worker threads(“http-nio-n”) to recieve more incoming requests.&lt;/p&gt;

&lt;p&gt;This can be easily achieved using &lt;a href=&quot;https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/context/request/async/DeferredResult.html&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DeferredResult&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A typical implementation in Java / Spring looks like this:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nd&quot;&gt;@GetMapping&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/deferred&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DeferredResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ResponseEntity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getDeferredResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;CompletableFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;completableFuture&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deferredResultService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDelayedResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;DeferredResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ResponseEntity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deferredResult&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DeferredResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;completableFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;thenAccept&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deferredResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hasResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;deferredResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ResponseEntity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HttpStatus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;OK&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;});&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;completableFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;exceptionally&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;});&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deferredResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DeferredResultService&lt;/code&gt; instead of returning the actual result, just returns the future, whose actual implementation happens in a worker thread&lt;/p&gt;

&lt;p&gt;If we run benchmark this API using &lt;a href=&quot;https://httpd.apache.org/docs/2.4/programs/ab.html&quot;&gt;ab&lt;/a&gt; by firing 100 requests concurrently, we see that it consumers only ~30 http-nio-n threads.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PS D:\apache\Apache24\bin&amp;gt; ./ab -n 100 -c 100 http://localhost:8080/deferred
This is ApacheBench, Version 2.3 &amp;lt;$Revision: 1879490 $&amp;gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking localhost (be patient).....done


Server Software:
Server Hostname:        localhost
Server Port:            8080

Document Path:          /deferred
Document Length:        8 bytes

Concurrency Level:      100
Time taken for tests:   20.030 seconds
Complete requests:      100
Failed requests:        0
Total transferred:      14000 bytes
HTML transferred:       800 bytes
Requests per second:    4.99 [#/sec] (mean)
Time per request:       20029.525 [ms] (mean)
Time per request:       200.295 [ms] (mean, across all concurrent requests)
Transfer rate:          0.68 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.3      0       1
Processing: 10008 10014   3.9  10015   10022
Waiting:    10004 10014   4.0  10015   10022
Total:      10008 10014   3.9  10015   10022

Percentage of the requests served within a certain time (ms)
  50%  10015
  66%  10016
  75%  10017
  80%  10017
  90%  10020
  95%  10021
  98%  10022
  99%  10022
 100%  10022 (longest request)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/threads.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Check out the demo project in my &lt;a href=&quot;https://github.com/madhur/deferred-result&quot;&gt;github repository&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Conventional Commits</title>
   <link href="https://madhur.co.in/blog/2021/11/13/conventional-commits.html"/>
   <updated>2021-11-13T00:00:00+05:30</updated>
   <id>id:/blog/2021/11/13/conventional-commits</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://www.conventionalcommits.org/en/v1.0.0/#specification&quot;&gt;Conventional Commits&lt;/a&gt; is a an effort to standardizing writing better git commit messages.&lt;/p&gt;

&lt;p&gt;As per it, a commit message should be structured as follows&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;type&amp;gt;[optional scope]: &amp;lt;description&amp;gt;

[optional body]

[optional footer(s)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We recently standardized writing commit messages in our team according to this spec. This can be even forced through &lt;a href=&quot;https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks&quot;&gt;git commit hooks&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/sh&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;commit_regex_normal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;(((feat|docs|style|refactor|perf|test|build|ci|chore|revert)(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\w&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;{0,15})&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)?))(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.*&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\S&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.*)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;commit_regex_bug_fix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;(((Fix)(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\w&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;{0,15})&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)?))(&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)([A-Z]+-[0-9]+:)(.*&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\S&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.*)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;commit_regex_auto_gen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;(Merge.*)|(Revert.*)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;|&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;commit_regex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$commit_regex_normal$o$commit_regex_bug_fix$o$commit_regex_auto_gen&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;error_msg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'       /‾‾‾‾‾‾‾‾
    &amp;lt;  Please use semantic commit messages(see https://www.conventionalcommits.org/en/v1.0.0 )
       \________

  &amp;lt;type&amp;gt;[&amp;lt;scope&amp;gt;]: &amp;lt;short summary&amp;gt;
     │     |              │
     │   (optional)       └─&amp;gt; Summary in present tense. Not capitalized. No period at the end.
     │
     └─&amp;gt; Type: chore, docs, feat, fix, refactor, style, or test.
    fix[&amp;lt;scope&amp;gt;]: ABC-1234 summary (Jira id mandatory for type -fix)

'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-iqE&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;commit_regex&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;error_msg&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&amp;amp;2
    &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1
&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Querying AWS ALB Logs using Athena</title>
   <link href="https://madhur.co.in/blog/2021/11/06/querying-alb-logs-aws-athena.html"/>
   <updated>2021-11-06T00:00:00+05:30</updated>
   <id>id:/blog/2021/11/06/querying-alb-logs-aws-athena</id>
   <content type="html">&lt;p&gt;Recently, I had a requirement of querying &lt;a href=&quot;https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html#:~:text=Elastic%20Load%20Balancing%20automatically%20distributes,only%20to%20the%20healthy%20targets.&quot;&gt;AWS Application Load Balancer&lt;/a&gt; Logs to get some data around request/ sec and p95 latencies.&lt;/p&gt;

&lt;p&gt;The Application load balancer logs are stored in &lt;a href=&quot;https://aws.amazon.com/s3/&quot;&gt;AWS S3&lt;/a&gt; by default and follows a consistent format which is &lt;a href=&quot;https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html&quot;&gt;documented here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/athena/?whats-new-cards.sort-by=item.additionalFields.postDateTime&amp;amp;whats-new-cards.sort-order=desc&quot;&gt;AWS Athena&lt;/a&gt; is the best tool to query such logs.&lt;/p&gt;

&lt;h2 id=&quot;best-practices-using-aws-athena&quot;&gt;Best practices using AWS Athena&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Make sure you specify the time period when querying Athena, else the data scanned will be very huge and you will end up paying lot more.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To find out the relevant time period to query, have a look at the &lt;a href=&quot;https://aws.amazon.com/cloudwatch/&quot;&gt;AWS Cloudwatch&lt;/a&gt; metrics and find intreseting patterns such as spikes in request count, response time etc&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If your ALB has comples routing logic, make sure to specify the &lt;a href=&quot;https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-target-groups.html&quot;&gt;Target group&lt;/a&gt; in the query&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;find-url-and-times-it-was-called-within-the-specified-time-period&quot;&gt;Find url and times it was called within the specified time period&lt;/h3&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;alb_logs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;&amp;lt;alb_name&amp;gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'2021'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'10'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'24'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;request_creation_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021-10-24T13:37:00.000000Z'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_creation_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021-10-24T13:38:00.000000Z'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_url&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;find-p95-latency-by-url&quot;&gt;Find p95 Latency by url&lt;/h3&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;approx_percentile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_processing_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p95&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;alb_logs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;&amp;lt;alb_name&amp;gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'2021'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'10'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'24'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_creation_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021-10-24T13:43:00.000000Z'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_creation_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2021-10-24T13:44:00.000000Z'&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request_url&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p95&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Backup and Restore specific cassandra tables</title>
   <link href="https://madhur.co.in/blog/2021/10/30/backup-and-restore-specific-cassandra-tables.html"/>
   <updated>2021-10-30T00:00:00+05:30</updated>
   <id>id:/blog/2021/10/30/backup-and-restore-specific-cassandra-tables</id>
   <content type="html">&lt;p&gt;Recently, we had to make alterations directly to production cassandra tables due to an urgent bug fix and required to backup and restore specific cassandra tables so that we could roll back incase something gone wrong.&lt;/p&gt;

&lt;p&gt;Backup and restoring tables is seamless using &lt;a href=&quot;https://cassandra.apache.org/doc/latest/cassandra/tools/nodetool/nodetool.html&quot;&gt;nodetool&lt;/a&gt; and &lt;a href=&quot;https://cassandra.apache.org/doc/latest/cassandra/tools/sstable/sstableloader.html&quot;&gt;sstableloader&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;cassandra-table-backup-steps&quot;&gt;Cassandra table backup steps&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Login to Casandra Box&lt;/li&gt;
  &lt;li&gt;Execute the following commands from the cassandra bin directory&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   ./nodetool snapshot -cf &amp;lt;tablename&amp;gt; &amp;lt;keyspace&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Repeat the same for any other table to be backed up&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This will create snapshots in the data directory at following locations:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  cassandra/data/data/&amp;lt;keyspace&amp;gt;/&amp;lt;table&amp;gt;-&amp;lt;UID&amp;gt;/snapshots/&amp;lt;epoch&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;cassandra-table-restore-steps&quot;&gt;Cassandra table restore steps&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Login to cassandra box&lt;/li&gt;
  &lt;li&gt;Navigate to following folder&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  cassandra/data/data/f&amp;lt;keyspace&amp;gt;/&amp;lt;table&amp;gt;-&amp;lt;UID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Execute following command&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  cp snapshots/&amp;lt;epoch&amp;gt;/*.* .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Repeat the same for any other table to be restored&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once all the snapshots have been copied to data directory, run following commands in sequence:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  ./nodetool refresh &amp;lt;keyspace&amp;gt; &amp;lt;table&amp;gt;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Using sshpass to skip entering passwords for SSH</title>
   <link href="https://madhur.co.in/blog/2021/10/23/using-sshpass-to-skip-entering-password.html"/>
   <updated>2021-10-23T00:00:00+05:30</updated>
   <id>id:/blog/2021/10/23/using-sshpass-to-skip-entering-password</id>
   <content type="html">&lt;p&gt;If your server does not allow key based login, you might need to enter password each time you want to ssh into.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh&lt;/code&gt; does not allow entering password into the command line.&lt;/p&gt;

&lt;p&gt;There is a nifty tool to allow exactly that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sshpass&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install sshpass
$ sshpass -p your_password ssh user@hostname
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On Mac&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;brew install hudochenkov/sshpass/sshpass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Running Spark on Windows</title>
   <link href="https://madhur.co.in/blog/2021/10/16/running-spark-on-windows.html"/>
   <updated>2021-10-16T00:00:00+05:30</updated>
   <id>id:/blog/2021/10/16/running-spark-on-windows</id>
   <content type="html">&lt;p&gt;Assuming you have spark downloaded on machine, you would run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./spark-class org.apache.spark.deploy.master.Master&lt;/code&gt; to run the Spark Master controller&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PS D:\spark\spark\bin&amp;gt;  ./spark-class org.apache.spark.deploy.master.Master
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/16 09:53:02 INFO Master: Started daemon with process name: 4804@DESKTOP-QCP2G4K
21/10/16 09:53:02 WARN Shell: Did not find winutils.exe: {}
21/10/16 09:53:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/10/16 09:53:02 INFO SecurityManager: Changing view acls to: user
21/10/16 09:53:02 INFO SecurityManager: Changing modify acls to: user
21/10/16 09:53:02 INFO SecurityManager: Changing view acls groups to:
21/10/16 09:53:02 INFO SecurityManager: Changing modify acls groups to:
21/10/16 09:53:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
21/10/16 09:53:03 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
21/10/16 09:53:03 INFO Master: Starting Spark master at spark://172.21.128.1:7077
21/10/16 09:53:03 INFO Master: Running Spark version 3.1.2
21/10/16 09:53:03 INFO Utils: Successfully started service 'MasterUI' on port 8080.
21/10/16 09:53:03 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://DESKTOP-QCP2G4K.mshome.net:8080
21/10/16 09:53:03 INFO Master: I have been elected leader! New state: ALIVE
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The spark UI will now be running at http://localhost:8080&lt;/p&gt;

&lt;p&gt;Now, we want to run the spark executor using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./spark-class org.apache.spark.deploy.worker.Worker spark://172.21.128.1:7077&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PS D:\spark\spark\bin&amp;gt; ./spark-class org.apache.spark.deploy.worker.Worker spark://172.21.128.1:7077
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/16 09:56:12 INFO Worker: Started daemon with process name: 8800@DESKTOP-QCP2G4K
21/10/16 09:56:12 WARN Shell: Did not find winutils.exe: {}
21/10/16 09:56:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/10/16 09:56:12 INFO SecurityManager: Changing view acls to: user
21/10/16 09:56:12 INFO SecurityManager: Changing modify acls to: user
21/10/16 09:56:12 INFO SecurityManager: Changing view acls groups to:
21/10/16 09:56:12 INFO SecurityManager: Changing modify acls groups to:
21/10/16 09:56:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
21/10/16 09:56:12 INFO Utils: Successfully started service 'sparkWorker' on port 57088.
21/10/16 09:56:12 INFO Worker: Worker decommissioning not enabled, SIGPWR will result in exiting.
21/10/16 09:56:13 INFO Worker: Starting Spark worker 172.21.128.1:57088 with 12 cores, 30.9 GiB RAM
21/10/16 09:56:13 INFO Worker: Running Spark version 3.1.2
21/10/16 09:56:13 INFO Worker: Spark home: D:\spark\spark\bin\..
21/10/16 09:56:13 INFO ResourceUtils: ==============================================================
21/10/16 09:56:13 INFO ResourceUtils: No custom resources configured for spark.worker.
21/10/16 09:56:13 INFO ResourceUtils: ==============================================================
21/10/16 09:56:13 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/10/16 09:56:13 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://DESKTOP-QCP2G4K.mshome.net:8081
21/10/16 09:56:13 INFO Worker: Connecting to master 172.21.128.1:7077...
21/10/16 09:56:13 INFO TransportClientFactory: Successfully created connection to /172.21.128.1:7077 after 21 ms (0 ms spent in bootstraps)
21/10/16 09:56:13 INFO Worker: Successfully registered with master spark://172.21.128.1:7077
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Spark is now ready to be used in any application such as Java.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nd&quot;&gt;@Configuration&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkConfig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@Value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${spark.app.name}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${spark.master}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masterUri&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@Bean&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;SparkConf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setAppName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;local-1634217252353&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setMaster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark://172.21.128.1:7077&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@Bean&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JavaSparkContext&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;JavaSparkContext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JavaSparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>zsh Autocomplete</title>
   <link href="https://madhur.co.in/blog/2021/10/09/zsh-autocomplete.html"/>
   <updated>2021-10-09T00:00:00+05:30</updated>
   <id>id:/blog/2021/10/09/zsh-autocomplete</id>
   <content type="html">&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zsh&lt;/code&gt; shell by default does not come with auto suggestions facility unlike fish shell.&lt;/p&gt;

&lt;p&gt;If you are looking for auto suggestions similar to fish, have a look at https://github.com/zsh-users/zsh-autosuggestions&lt;/p&gt;

&lt;p&gt;For MAC OS, following steps are required to install&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Add into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.zshrc&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;plugins=( 
    # other plugins...
    zsh-autosuggestions
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Designing Change Data Capture</title>
   <link href="https://madhur.co.in/blog/2021/08/20/design-change-data-capture.html"/>
   <updated>2021-08-20T00:00:00+05:30</updated>
   <id>id:/blog/2021/08/20/design-change-data-capture</id>
   <content type="html">&lt;p&gt;Change Data Capture (CDC) is a very important topic for any backend developer to understand. Lot of systems backbone is based on Change data capture.&lt;/p&gt;

&lt;p&gt;When I started my career as a backend developer, I did not have any understand of CDC. It is only after talking to some of the industry experts, I realized how important this topic is.&lt;/p&gt;

&lt;p&gt;In this post, we will try to understand what is CDC and its practical usages:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Change Data Capture is a software process that identifies and tracks changes to data in a source database. The source database can be relational or any database for that matter. CDC provides real time or near real time movement of data by moving and processing data continuously as new database events occur.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One of the example of CDC is Microsoft’s Cosmos DB Change Feed&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed&quot;&gt;Change feed in Azure Cosmos DB&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://debezium.io/&quot;&gt;Debezium&lt;/a&gt; is another solution which provides CDC for the databases such as MySQL&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;change-data-capture-methods&quot;&gt;Change data capture Methods&lt;/h2&gt;

&lt;h3 id=&quot;audit-columns&quot;&gt;Audit Columns&lt;/h3&gt;

&lt;p&gt;By using columns such as LAST_UPDATED, DATE_MODIFIED columns. The application can query the rows which have modified that changed since data was last extracted and publish into the stream.&lt;/p&gt;

&lt;h3 id=&quot;trigger-based-cdc&quot;&gt;Trigger Based CDC&lt;/h3&gt;

&lt;p&gt;Defining database triggers that fire after INSERT, UPDATE OR DELETE commands are another method use to create a change log. Some databases have native support for triggers.&lt;/p&gt;

&lt;h3 id=&quot;log-based-cdc&quot;&gt;Log based CDC&lt;/h3&gt;

&lt;p&gt;Databases support transaction logs that store all database events. With log based CDC, new database transactions are read from source database native transaction logs.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The changes are captured without making application level changes and without having to &amp;gt; scan operational tables, both of which add additional workload and reduce source &amp;gt; systems’ performance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;using-cdc-to-implement-the-outbox-pattern&quot;&gt;Using CDC to implement the Outbox Pattern&lt;/h2&gt;

&lt;p&gt;Content taken from https://debezium.io/blog/2020/02/10/event-sourcing-vs-cdc/&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The primary goal of the Outbox Pattern is to ensure that updates to the application  state (stored in tables) and publishing of the respective domain event is done within a  single transaction. This involves creating an Outbox table in the database to collect  those domain events as part of a transaction. Having transactional guarantees around the  domain events and their propagation via the Outbox is important for data consistency  across a system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;After the transaction completes, the domain events are then picked up by a CDC  connector and forwarded to interested consumers using a reliable message broker (see  Figure 5). Those consumers may then use the domain events to materialize their own  aggregates (see above per Event Sourcing)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/Blog/cdc.png&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Liveness and Readiness Probes</title>
   <link href="https://madhur.co.in/blog/2021/08/14/liveness-and-readiness-probes.html"/>
   <updated>2021-08-14T00:00:00+05:30</updated>
   <id>id:/blog/2021/08/14/liveness-and-readiness-probes</id>
   <content type="html">&lt;p&gt;When working with Kubernetes, &lt;a href=&quot;https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/&quot;&gt;Liveness and Readiness Probes&lt;/a&gt; are very important concepts to understand.&lt;/p&gt;

&lt;h2 id=&quot;readiness-probe&quot;&gt;Readiness Probe&lt;/h2&gt;

&lt;p&gt;Kubernetes fires readiness probe to the pod to determine if the pod is ready to serve traffic or not.&lt;/p&gt;

&lt;p&gt;It can simply be defined as&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;readinessProbe&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cat&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/tmp/healthy&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;initialDelaySeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;periodSeconds&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can also provide readiness probe as HTTP or TCP commands&lt;/p&gt;

&lt;h2 id=&quot;liveness-probe&quot;&gt;Liveness Probe&lt;/h2&gt;

&lt;p&gt;Kubernetes fires readiness probe to the pod to determine if the pod is alive. If the pod is not alive, Kubernetes will restart the pod.&lt;/p&gt;

&lt;p&gt;An important point to be noted is&lt;/p&gt;

&lt;p&gt;` Liveness probes do not wait for readiness probes to succeed. If you want to wait before executing a liveness probe you should use initialDelaySeconds or a startupProbe.`&lt;/p&gt;

&lt;p&gt;Which means that liveness probe and readiness probes have no dependency on each other. Some people assume that liveness probe start only after readiness probe is successful. This is misconception and is incorrect.&lt;/p&gt;

&lt;h3 id=&quot;how-to-determine-the-value-of-these-probes&quot;&gt;How to determine the value of these probes&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Determine the max start-up time taken by the application server to successfully start accepting http connections.
For example, in our case pod takes around 15 seconds in all different environments.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Assuming a buffer of about 15 seconds we set the liveness probe to 30 seconds, with the default retry of 3 times and time difference between each retry as 5 seconds (these default value are set in periodSeconds and failureThreshold for each probe).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This leads to liveness probe being successful in the worst case scenario up to 45 seconds.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;With another buffer of 15 seconds we set the readiness probe for 60 seconds.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;startup-probes&quot;&gt;Startup Probes&lt;/h2&gt;

&lt;p&gt;Kubernetes introduced a new type of probe called startup probe to introduce the delay for liveness probes.&lt;/p&gt;

&lt;p&gt;As per kubernetes&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sometimes, you have to deal with legacy applications that might require an additional startup time on their first initialization. In &amp;gt; such cases, it can be tricky to set up liveness probe parameters without compromising the fast response to deadlocks that motivated such &amp;gt; a probe. The trick is to set up a startup probe with the same command, HTTP or TCP check, with a failureThreshold * periodSeconds long &amp;gt; enough to cover the worse case startup time.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Meaning of at-least once, at-most once and exactly-once delivery</title>
   <link href="https://madhur.co.in/blog/2021/07/18/meaning-of-at-least-once-at-most-once-and-exactly-once-delivery.html"/>
   <updated>2021-07-18T00:00:00+05:30</updated>
   <id>id:/blog/2021/07/18/meaning-of-at-least-once-at-most-once-and-exactly-once-delivery</id>
   <content type="html">&lt;p&gt;Ever since I have started working with Kafka, I have came across these terms very frequently, At-least once, At-most once and Exactly Once.&lt;/p&gt;

&lt;p&gt;As an engineer, It is very important to understand these concepts.&lt;/p&gt;
&lt;h2 id=&quot;at-most-once-configuration&quot;&gt;At-most once Configuration&lt;/h2&gt;

&lt;p&gt;As the name suggests, At-most-once means the message will be delivered at-most once. Once delivered, there is no chance of delivering again. If the consumer is unable to handle the message due to some exception, the message is lost. This is because Kafka is automatically committing the last offset used.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;enable.auto.commit&lt;/code&gt; to true&lt;/li&gt;
  &lt;li&gt;Set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;auto.commit.interval.ms&lt;/code&gt; to low value&lt;/li&gt;
  &lt;li&gt;Since &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;auto.commit&lt;/code&gt; is set to true, there is no need to call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.commitSync()&lt;/code&gt; from the consumer.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that it is also possible to have at-lest-once scenario with the same configuration. Let’s say consumer successfully processed the message successfully into its store and in the meantime before kafka could commit the offset, consumer was restarted. In this scenario, consumer would again get the same message.&lt;/p&gt;

&lt;p&gt;Hence, even if using at-most once or at-least once configuration, consumer should be always prepared to handle the duplicates.&lt;/p&gt;

&lt;h2 id=&quot;at-least-once-configuration&quot;&gt;At-least once configuration&lt;/h2&gt;
&lt;p&gt;At-least once as the name suggests, message will be delivered atleast once. There is high chance that message will be delivered again as duplicate.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;enable.auto.commit&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;false&lt;/code&gt; OR&lt;/li&gt;
  &lt;li&gt;Consumer should now then take control of the message offset commits to Kafka by making the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.commitSync()&lt;/code&gt; call.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s say consumer has processed the messages and committed the messages to its local store, but consumer crashes and did not get a chance to commit offset to Kafka before it has crashed. When consumer restarts, Kafka would deliver messages from the last offset, resulting in duplicates.&lt;/p&gt;

&lt;h2 id=&quot;exactly-once-configuration&quot;&gt;Exactly-once configuration&lt;/h2&gt;

&lt;p&gt;Exactly-once as the name suggests, there will be only one and once message delivery. It difficult to achieve in practice.&lt;/p&gt;

&lt;p&gt;In this case offset needs to be manually managed.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Set &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;enable.auto.commit&lt;/code&gt; to false&lt;/li&gt;
  &lt;li&gt;Do not make call to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.commitSync()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Implement a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ConsumerRebalanceListener&lt;/code&gt; and within the listener perform &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.seek(topicPartition,offset);&lt;/code&gt; to start reading from a specific offset of that topic/partition.&lt;/li&gt;
  &lt;li&gt;While processing the messages, get hold of the offset of each message. Store the processed message’s offset in an atomic way along with the processed message using atomic-transaction. When data is stored in relational database atomicity is easier to implement. For non-relational data-store such as HDFS store or No-SQL store one way to achieve atomicity is as follows: Store the offset along with the message.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>How tinyUrl Does redirection</title>
   <link href="https://madhur.co.in/blog/2021/07/11/how-tinyurl-does-redirection.html"/>
   <updated>2021-07-11T00:00:00+05:30</updated>
   <id>id:/blog/2021/07/11/how-tinyurl-does-redirection</id>
   <content type="html">&lt;p&gt;I got curious about how tinyUrl does redirection for its Url. Is it standard browser redirect with 301/302 status code or something else?&lt;/p&gt;

&lt;p&gt;With that created this tinyUrl &lt;a href=&quot;https://tinyurl.com/madhur25&quot;&gt;tinyurl.com/madhur25&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Figured out that it was indeed a browser redirect using 301 status code.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ curl https://tinyurl.com/madhur25 -vvv
* STATE: INIT =&amp;gt; CONNECT handle 0x600057310; line 1407 (connection #-5000)
* Added connection 0. The cache now contains 1 members
*   Trying 104.20.138.65...
* TCP_NODELAY set
* STATE: CONNECT =&amp;gt; WAITCONNECT handle 0x600057310; line 1460 (connection #0)
* Connected to tinyurl.com (104.20.138.65) port 443 (#0)
* STATE: WAITCONNECT =&amp;gt; SENDPROTOCONNECT handle 0x600057310; line 1567 (connection #0)
* Marked for [keep alive]: HTTP default
* ALPN, offering http/1.1
* Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH
* successfully set certificate verify locations:
*   CAfile: /usr/ssl/certs/ca-bundle.crt
  CApath: none
* TLSv1.2 (OUT), TLS header, Certificate Status (22):
* TLSv1.2 (OUT), TLS handshake, Client hello (1):
* STATE: SENDPROTOCONNECT =&amp;gt; PROTOCONNECT handle 0x600057310; line 1581 (connection #0)
* TLSv1.2 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Client hello (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS change cipher, Client hello (1):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-ECDSA-AES128-GCM-SHA256
* ALPN, server accepted to use http/1.1
* Server certificate:
*  subject: C=US; ST=California; L=San Francisco; O=Cloudflare, Inc.; CN=sni.cloudflaressl.com
*  start date: Jul  3 00:00:00 2021 GMT
*  expire date: Jul  2 23:59:59 2022 GMT
*  subjectAltName: host &quot;tinyurl.com&quot; matched cert's &quot;tinyurl.com&quot;
*  issuer: C=US; O=Cloudflare, Inc.; CN=Cloudflare Inc ECC CA-3
*  SSL certificate verify ok.
* STATE: PROTOCONNECT =&amp;gt; DO handle 0x600057310; line 1602 (connection #0)
&amp;gt; GET /madhur25 HTTP/1.1
&amp;gt; Host: tinyurl.com
&amp;gt; User-Agent: curl/7.51.0
&amp;gt; Accept: */*
&amp;gt;
* STATE: DO =&amp;gt; DO_DONE handle 0x600057310; line 1664 (connection #0)
* STATE: DO_DONE =&amp;gt; WAITPERFORM handle 0x600057310; line 1791 (connection #0)
* STATE: WAITPERFORM =&amp;gt; PERFORM handle 0x600057310; line 1801 (connection #0)
* HTTP 1.1 or later with persistent connection, pipelining supported
&amp;lt; HTTP/1.1 301 Moved Permanently
&amp;lt; Date: Sun, 11 Jul 2021 04:11:01 GMT
&amp;lt; Content-Type: text/html; charset=UTF-8
&amp;lt; Transfer-Encoding: chunked
&amp;lt; Connection: keep-alive
&amp;lt; X-Powered-By: PHP/7.3.28
&amp;lt; Location: https://www.madhur.co.in/
&amp;lt; Cache-Control: max-age=0, public, s-max-age=900, stale-if-error: 86400
&amp;lt; Referrer-Policy: unsafe-url
&amp;lt; Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
&amp;lt; CF-Cache-Status: DYNAMIC
&amp;lt; Expect-CT: max-age=604800, report-uri=&quot;https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct&quot;
* Server cloudflare is not blacklisted
&amp;lt; Server: cloudflare
&amp;lt; CF-RAY: 66cf2f6e7e293c13-BLR
&amp;lt; alt-svc: h3-27=&quot;:443&quot;; ma=86400, h3-28=&quot;:443&quot;; ma=86400, h3-29=&quot;:443&quot;; ma=86400, h3=&quot;:443&quot;; ma=86400
&amp;lt;
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
    &amp;lt;head&amp;gt;
        &amp;lt;meta charset=&quot;UTF-8&quot; /&amp;gt;
        &amp;lt;meta http-equiv=&quot;refresh&quot; content=&quot;0;url='https://www.madhur.co.in/'&quot; /&amp;gt;

        &amp;lt;title&amp;gt;Redirecting to https://www.madhur.co.in/&amp;lt;/title&amp;gt;
    &amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
        Redirecting to &amp;lt;a href=&quot;https://www.madhur.co.in/&quot;&amp;gt;https://www.madhur.co.in/&amp;lt;/a&amp;gt;.
    &amp;lt;/body&amp;gt;
* STATE: PERFORM =&amp;gt; DONE handle 0x600057310; line 1965 (connection #0)
* multi_done
* Curl_http_done: called premature == 0
* Connection #0 to host tinyurl.com left intact
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Encoding and Hashing</title>
   <link href="https://madhur.co.in/blog/2021/07/06/encoding-and-hashing.html"/>
   <updated>2021-07-06T00:00:00+05:30</updated>
   <id>id:/blog/2021/07/06/encoding-and-hashing</id>
   <content type="html">&lt;h2 id=&quot;md5&quot;&gt;MD5&lt;/h2&gt;

&lt;p&gt;MD5 is hashing algorithm. It produces 128 bit value&lt;/p&gt;

&lt;h2 id=&quot;base64-encoding&quot;&gt;Base64 Encoding&lt;/h2&gt;

&lt;p&gt;Base64 character encodes 6 bits of the hash value. So if we use base64 encoding of above value, it will contain 21 characters&lt;/p&gt;
</content>
 </entry>
 
 
</feed>