<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="content-type" content="text/html; charset=utf-8" />
   <title>Evaluation Methods for Machine Learning &larr; Inductio Ex Machina</title>
   <meta name="author" content="Mark Reid" />

   <link rel='openid.server' href='http://www.myopenid.com/server' />
   <link rel='openid.delegate' href='http://mark.reid.name' />

   <link rel="start" href="/" />

	
	
	
  	<link rel="alternate" type="application/atom+xml" href="atom.xml" title="RSS feed" />
	

   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="/files/css/syntax.css" type="text/css" />

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="/files/css/screen.css" type="text/css" />

</head>
<body id="">
<div id="site">

  
<div id="header">
	<h1>
	<a href="/iem/" title="A machine learning blog">Inductio ex Machina</a>
	<span class="byline">&larr; <a href="/">Mark Reid</a></span>
</h1>
<ul class="nav">
  <li><a class="home" href="/iem/">Home</a></li>
  <li><a class="info" href="/iem/info.html">Info</a></li>
  <li><a class="past" href="/iem/past.html">Past</a></li>
  <li><a class="kith" href="/iem/kith.html">Kith</a></li>
</ul>

</div>

<div id="page">
	
  <h1 class="emphnext">Evaluation Methods for Machine Learning</h1>

<p>Although I wasn&#8217;t able to attend the talks at <a href='http://icml2008.cs.helsinki.fi/'>ICML 2008</a> I was able to participate in the <a href='http://www.site.uottawa.ca/ICML08WS/'>Workshop on Evaluation Methods for Machine Learning</a> run by William Klement, <a href='http://www.site.uottawa.ca/~cdrummon/'>Chris Drummond</a>, and <a href='http://www.site.uottawa.ca/~nat/'>Nathalie Japkowicz</a>.</p>

<p>This workshop at ICML was a continuation of previous workshops held at AAAI that aim to cast a critical eye on the methods used in machine learning to experimentally evaluate the performance of algorithms.</p>

<p>It kicked off with a series of mini debates with Nathalie and Chris articulating the opposing sides. The questions included the following:</p>

<ul>
<li>Should we change how evaluation is done?</li>

<li>Is evaluation central to empirical work?</li>

<li>Are statistical tests critical to evaluation?</li>

<li>Are the UCI data sets sufficient for evaluation?</li>
</ul>

<p>There were three papers I particularly liked: <a href='http://www.ailab.si/janez/'>Janez Demsar</a>&#8217;s talk &#8221;<a href='http://www.site.uottawa.ca/ICML08WS/papers/J_Demsar.pdf'>On the Appropriateness of Statistical Tests in Machine Learning</a>&#8221;, <a href='http://www.cs.cmu.edu/~elaw/'>Edith Law</a>&#8217;s &#8221;<a href='http://www.site.uottawa.ca/ICML08WS/papers/E_Law.pdf'>The Problem of Accuracy as an Evaluation Criterion</a>&#8221;, and <a href='http://www.site.uottawa.ca/~cdrummon/'>Chris Drummond</a>&#8217;s call for a mild-mannered revolution &#8221;<a href='http://www.site.uottawa.ca/ICML08WS/papers/C_Drummond.pdf'>Finding a Balance between Anarchy and Orthodoxy</a>&#8221;.</p>

<p>Janez&#8217;s talk touched on a number of criticisms that <a href='http://conflate.net/inductio/2008/04/the-earth-is-round/'>I had found in Jacob Cohen&#8217;s paper &#8220;The Earth is Round (p &lt; 0.05)&#8221;</a> making the case that people often incorrectly report and incorrectly interpret p-values for statistical tests. Unfortunately, as Janez points out, since machine learning is a discipline that (rightly) places emphasis on results it is difficult as a reviewer to reject a paper that presents an ill-motivated and confusing idea if its authors have shown that, statistically, it outperforms similar approaches.</p>

<p>Edith&#8217;s talk argued that accuracy is sometimes a poor measure of performance making all this concern over whether we are constructing statistical tests for it (or AUC) moot. In particular, for tasks like salient region detection in images, language translation and music tagging there is no single correct region, translation or tag. Whether or not a particular region/translation/tag is &#8220;correct&#8221; or not is impossible to determine independent of the more difficult tasks of image recognition/language understanding/music identification. Solving these for the purposes of evaluation would make a solution to the smaller tasks redundant. Instead of focusing on evaluation of the smaller tasks, Edith suggests ways in which games that humans play on the web &#8211; such as the <a href='http://www.espgame.org/'>ESP Game</a> &#8211; can be used to evaluate machine performance on these tasks by playing learning algorithms against humans.</p>

<p>Finally, Chris&#8217;s talk made the bold claim that the way we approach evaluation in machine learning is an &#8220;impoverished realization of a controversial methodology&#8221;, namely statistical hypothesis testing. &#8220;Impoverished&#8221; because when we do do hypothesis testing it is in the narrowest of senses, mainly to test that my algorithm is better than yours on this handful of data sets. &#8220;Controversial&#8221; since many believe science to have social, exploratory and accidental aspects &#8212; much more than just the clinical proposing of hypotheses for careful testing.</p>

<p>What these papers and the workshop as a whole showed me was how unresolved my position is on these and other questions regarding evaluation. On the one hand I spent a lot of time painstakingly setting up, running and analysing experiments for my <a href='http://www.library.unsw.edu.au/~thesis/adt-NUN/public/adt-NUN20070512.173744/index.html'>PhD research</a> on inductive transfer in order to evaluate the methods I was proposing. I taught myself how to correctly control for confounding factors, use the <a href='http://en.wikipedia.org/wiki/Bonferroni_correction'>Bonferroni correction</a> to adjust significance levels and other esoterica of statistical testing. Applying all these procedures carefully to my work felt very scientific and I was able to create many pretty graphs and tables replete with confidence intervals, p-values and the like. On the other hand &#8211; and with sufficient hindsight &#8211; it&#8217;s not clear how much value this type of analysis added to the thesis overall (apart from demonstrating to my reviewers that I could do it).</p>

<p>The dilemma is this: when one algorithm or approach clearly dominates another details such as p-values, t-tests and the like only obscure the results; and when two algorithms are essentially indistinguishable using &#8220;significance&#8221; levels to pry them apart seems to be grasping at straws.</p>

<p>That&#8217;s not to say that we should get rid of empirical evaluation all together. Rather, we should carefully choose (or create) our data sets and empirical questions so as to gain as much insight as possible and go beyond &#8220;my algorithm is better than yours&#8221;. Statistical tests should not mark the end of an experimental evaluation but rather act as a starting point for further questions and carefully constructed experiments that resolve those questions.</p>

  <address class="signature">
    <a class="author" href="http://mark.reid.name">Mark Reid</a> 
    <span class="date">21 July 2008</span>
    <span class="location">Canberra, Australia</span>
  </address>
</div><!-- End Page -->

<!-- Delicious hits
<script type="text/javascript">
    if (typeof window.Delicious == "undefined") window.Delicious = {};
    Delicious.BLOGBADGE_DEFAULT_CLASS = 'delicious-blogbadge-line';
</script>
<script src="http://static.delicious.com/js/blogbadge.js"></script>
-->


<!-- Discus Comments -->
<div id="disqus_thread"></div>

<!-- Enable Disqus comments -->
<script type="text/javascript">
	var disqus_iframe_css = "http://mark.reid.name/css/screen.css";
	var disqus_title = "Evaluation Methods for Machine Learning";
	var disqus_message = "Some thoughts on the workshop on evaluation methods that I attended as part of ICML 2008 in Helsinki.";
</script>
<script type="text/javascript" src="http://disqus.com/forums/markreid/embed.js"></script>

<noscript>
		<a href="http://markreid.disqus.com/?url=ref">View the discussion thread.</a>
</noscript>

  
  <div id="footer">
	<address>
		<span class="copyright">
			Content &amp; Design by 
			<a href="/info/site.html">Mark Reid</a>
			<br/>
			(<a rel="licence" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Some rights reserved</a>)			
		</span>
		<span class="engine">
			Powered by 
			<a href="http://github.com/mreid/jekyll/" title="A static, minimalist CMS">Jekyll</a>
		</span>
	</address>
  </div>
</div>

<!-- Google Analytics script goes here -->
<script type="text/javascript" src="http://twitter.com/javascripts/blogger.js"></script>
<script type="text/javascript" src="http://twitter.com/statuses/user_timeline/mdreid.json?callback=t
witterCallback2&count=1"></script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-1051817-4");
pageTracker._trackPageview();
</script>
<!--[if IE 6]>
<script type="text/javascript"> 
	/*Load jQuery if not already loaded*/ if(typeof jQuery == 'undefined'){ document.write("<script type=\"text/javascript\"   src=\"http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js\"></"+"script>"); var __noconflict = true; } 
	var IE6UPDATE_OPTIONS = {
		icons_path: "http://static.ie6update.com/hosted/ie6update/images/"
	}
</script>
<script type="text/javascript" src="http://static.ie6update.com/hosted/ie6update/ie6update.js"></script>
<![endif]-->
</body>
</html>
